#The topic name to which the jobs will be written in Kafka
topic_name_tasks=my_topic2

#DB configuration
db_host=postgres
db_max_pool_size=15
db_password=mypassword
db_user=myuser
db_port=5432
db_name=mydb

#The minimum interval alowed in a job request between each execution
minimum_interval_time=300

#The HTTP version for the executions
notifications_http_version=1

#The total number of threads on the pool that executes the tasks
timer_threads_in_process=10

#PG admin user and password
PGADMIN_DEFAULT_EMAIL=username
PGADMIN_DEFAULT_PASSWORD=password

#Redis configuration
redis_port=6379
redis_listeners_key=listeners
cancel_request_channel=cancel_channel
redis_password=blabla!@#4


####### HOSTS you can change when splitting processes between different networks\servers #########
####### If you run it all on the same server with one docker-compose file (on the same network) than you don't need to change anything below ####
####### Chnage relevant hosts if you run the relevant process on a different network\server #######


#endpoint for sending link for cancellation or show job (sent on every execution)
#should be set where the endpoint process runs.
endpoint_host=localhost:8080
kafka_host=kafka
kafka_listener=PLAINTEXT://kafka:9092
redis_host=redis
db_host=postgres
